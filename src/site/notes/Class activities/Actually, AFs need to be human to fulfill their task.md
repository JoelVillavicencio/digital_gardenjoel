---
{"dg-publish":true,"permalink":"/class-activities/actually-a-fs-need-to-be-human-to-fulfill-their-task/"}
---

#Mappingnarrative 

What if to react accordingly to their teenagers' emotions they would require to have those emotions themselves?

Programmers could have said "F*&â€¢ off, having a standard computer program do the job is too difficult, let's just give them sentience". Or maybe clients didn't want to be disillusioned with a [Chinese room](https://en.wikipedia.org/wiki/Chinese_room) and exerted pressure on whatever tech company creates AFs to **make them real**.

I got the idea to write this note while I was being idle in TV Tropes, so it is fair to include the article that inspired it:
<iframe title="Ridiculously Human Robots" src="https://tvtropes.org/pmwiki/pmwiki.php/Main/RidiculouslyHumanRobots" allow="fullscreen" allowfullscreen="" style="height: 100%; width: 100%; aspect-ratio: 1 / 1;"></iframe>
This is not an image, it's an actual website.

Let's not forget that AFs are a replacement of humans, so making them as faulty as humans would not only be a rational decision, but _the goal_. 

It could also be related to ethics. Yes, to prevent the paperclip maximiser, let's just extend a bit nearer. A society that fears robots rebelling against humans might counteract this undesirable future by making robot morals the same as humans, which sounds like a good idea until you remember human morals cause genocide and discriminate certain demographics unnecessarily. For some people, the dangers of a fellow human might be preferable to the dangers of a superior being.

This video from Rational Animations explains the pros of human morality better than I can:
![](https://www.youtube.com/watch?v=gpBqw2sTD08)
The moment when Rosa doesn't perceive the taxi men punching each other as a fight could be a counterargument to the matching moralities point and the question in the beginning.

P.D. This defense doesn't disprove that Ishiguro just did it for the sake of impactful storytelling.